{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os, sys\n",
    "# Add the parent directory (one level up) to the Python path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from modules.inference import preprocessing, object_detection, nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict using model\n",
    "def yolo_predict(model, image, score_threshold = 0.5, nms_iou_threshold = 0.5):\n",
    "\n",
    "    #predict from model\n",
    "    predicted_outputs = model.predict(image)\n",
    "    bounding_boxes, class_categories, scores = model.post_processv2(predicted_outputs, score_threshold = score_threshold)\n",
    "\n",
    "    max_scores = [x[np.argmax[x]] for x in scores]\n",
    "\n",
    "    #nms\n",
    "    indices = nms.filter(bounding_boxes, max_scores, score_threshold=0.0, nms_iou_threshold=nms_iou_threshold)\n",
    "\n",
    "    filtered_boxes = [bounding_boxes[x] for x in indices]\n",
    "    filtered_scores = [scores[x] for x in indices]\n",
    "    filtered_categories = [class_categories[x] for x in indices]    \n",
    "\n",
    "\n",
    "    return filtered_boxes, filtered_categories, filtered_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model 1 and model 2\n",
    "yolo_model1 = object_detection.Model()\n",
    "yolo_model2 = object_detection.Model('../storage/models/yolo_model_2/yolov4-tiny-logistics_size_416_2.weights', \n",
    "                               '../storage/models/yolo_model_2/yolov4-tiny-logistics_size_416_2.cfg',\n",
    "                               '../storage/models/yolo_model_2/logistics.names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_dir = '../storage/data/dataset_predictions'\n",
    "data_dir = '../storage/data/dataset'\n",
    "data_paths = os.listdir(data_dir)\n",
    "image_paths = [os.path.join(data_dir, x) for x in data_paths if x.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m image_processed \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(image,\n\u001b[1;32m      6\u001b[0m                     scalefactor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.\u001b[39m,\n\u001b[1;32m      7\u001b[0m                     size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m416\u001b[39m, \u001b[38;5;241m416\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m                     crop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#get yolo 1 to predict\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m filtered_boxes2, filtered_categories2, filtered_scores2 \u001b[38;5;241m=\u001b[39m \u001b[43myolo_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43myolo_model2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_processed\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36myolo_predict\u001b[0;34m(model, image, score_threshold, nms_iou_threshold)\u001b[0m\n\u001b[1;32m      5\u001b[0m predicted_outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(image)\n\u001b[1;32m      6\u001b[0m bounding_boxes, class_categories, scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpost_processv2(predicted_outputs, score_threshold \u001b[38;5;241m=\u001b[39m score_threshold)\n\u001b[0;32m----> 8\u001b[0m max_scores \u001b[38;5;241m=\u001b[39m [x[np\u001b[38;5;241m.\u001b[39margmax[x]] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m scores]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#nms\u001b[39;00m\n\u001b[1;32m     11\u001b[0m indices \u001b[38;5;241m=\u001b[39m nms\u001b[38;5;241m.\u001b[39mfilter(bounding_boxes, max_scores, score_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, nms_iou_threshold\u001b[38;5;241m=\u001b[39mnms_iou_threshold)\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m predicted_outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(image)\n\u001b[1;32m      6\u001b[0m bounding_boxes, class_categories, scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpost_processv2(predicted_outputs, score_threshold \u001b[38;5;241m=\u001b[39m score_threshold)\n\u001b[0;32m----> 8\u001b[0m max_scores \u001b[38;5;241m=\u001b[39m [x[\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m scores]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#nms\u001b[39;00m\n\u001b[1;32m     11\u001b[0m indices \u001b[38;5;241m=\u001b[39m nms\u001b[38;5;241m.\u001b[39mfilter(bounding_boxes, max_scores, score_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, nms_iou_threshold\u001b[38;5;241m=\u001b[39mnms_iou_threshold)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#laod image\n",
    "image = cv2.imread(image_paths[0])\n",
    "\n",
    "#preprocess image using the same pipeline used before\n",
    "image_processed = cv2.dnn.blobFromImage(image,\n",
    "                    scalefactor = 1/255.,\n",
    "                    size = (416, 416),\n",
    "                    mean = (0, 0, 0),\n",
    "                    swapRB = True,\n",
    "                    crop = False\n",
    ")\n",
    "\n",
    "#get yolo 1 to predict\n",
    "filtered_boxes2, filtered_categories2, filtered_scores2 = yolo_predict(yolo_model2, image_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(filename, filtered_boxes, filtered_categories, filtered_scores):\n",
    "    \n",
    "    filename = filename\n",
    "    with open(filename, 'w') as file:\n",
    "        for i, id in enumerate(filtered_categories):\n",
    "                file.write(f\"{id}\")\n",
    "\n",
    "                for box in filtered_boxes[i]:\n",
    "                     file.write(f\" {box}\")\n",
    "                file.write(\" \" + \" \".join(str(score) for score in filtered_scores[i]))\n",
    "                file.write(f\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions('test.txt', bounding_boxes, class_categories, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't parse 'scores'. Sequence item with index 0 has a wrong type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m filtered_boxes2, filtered_categories2, filtered_scores2 \u001b[38;5;241m=\u001b[39m yolo_model2\u001b[38;5;241m.\u001b[39mpost_processv2(predicted_outputs, score_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#nms\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[43mnms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_boxes2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_scores2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnms_iou_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m filtered_boxes \u001b[38;5;241m=\u001b[39m [bounding_boxes[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[1;32m     23\u001b[0m filtered_scores \u001b[38;5;241m=\u001b[39m [scores[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m/mnt/c/Users/wsenevi1/Desktop/Classes/AI MASTERS/senevirathne-kaneel/techtrack/modules/inference/nms.py:11\u001b[0m, in \u001b[0;36mfilter\u001b[0;34m(boxes, scores, score_threshold, nms_iou_threshold)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mFilters bounding boxes using Non-Maximum Suppression (NMS).\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Apply the Non-Maximum Suppression using OpenCV's NMSBoxes\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNMSBoxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnms_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnms_iou_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Convert the result to a more usable format\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indices) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't parse 'scores'. Sequence item with index 0 has a wrong type"
     ]
    }
   ],
   "source": [
    "#save scores for the first 1000 image sin the techtrack dataset\n",
    "for image_path in image_paths[:1]:\n",
    "\n",
    "    #laod image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    #preprocess image using the same pipeline used before\n",
    "    image_processed = cv2.dnn.blobFromImage(image,\n",
    "                        scalefactor = 1/255.,\n",
    "                        size = (416, 416),\n",
    "                        mean = (0, 0, 0),\n",
    "                        swapRB = True,\n",
    "                        crop = False\n",
    "    )\n",
    "\n",
    "    predicted_outputs = yolo_model2.predict(image_processed)\n",
    "    filtered_boxes2, filtered_categories2, filtered_scores2 = yolo_model2.post_processv2(predicted_outputs, score_threshold = 0.5)\n",
    "           \n",
    "    #nms\n",
    "    indices = nms.filter(filtered_boxes2, filtered_scores2, score_threshold=0.0, nms_iou_threshold=0.25)\n",
    "\n",
    "    filtered_boxes = [bounding_boxes[x] for x in indices]\n",
    "    filtered_scores = [scores[x] for x in indices]\n",
    "    filtered_categories = [class_categories[x] for x in indices]    \n",
    "\n",
    "\n",
    "    #filenmae\n",
    "    file_name = image_path.split('/')[-1].replace('.jpg', '_pred.txt')\n",
    "    dest_path = os.path.join(destination_dir, file_name)\n",
    "    dest_path = 'test.txt'\n",
    "    save_predictions(dest_path, filtered_boxes2, filtered_categories2, filtered_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
